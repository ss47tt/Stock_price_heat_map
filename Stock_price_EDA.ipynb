{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "995b9cfa",
   "metadata": {},
   "source": [
    "### Download 60 days of half-hour period stock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9a7589b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading GOOG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOOG data saved to ./GOOG_60d_30m.csv\n",
      "\n",
      "Downloading AAPL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL data saved to ./AAPL_60d_30m.csv\n",
      "\n",
      "Downloading MSFT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSFT data saved to ./MSFT_60d_30m.csv\n",
      "\n",
      "Downloading TSLA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TSLA data saved to ./TSLA_60d_30m.csv\n",
      "\n",
      "Downloading NVDA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVDA data saved to ./NVDA_60d_30m.csv\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "# List of stock tickers\n",
    "tickers = [\"GOOG\", \"AAPL\", \"MSFT\", \"TSLA\", \"NVDA\"]  # Add as many as you like\n",
    "\n",
    "# Parameters\n",
    "period = \"60d\"\n",
    "interval = \"30m\"\n",
    "save_folder = \"./\"  # Folder to save CSVs\n",
    "\n",
    "for ticker in tickers:\n",
    "\tprint(f\"Downloading {ticker}...\")\n",
    "\t\n",
    "\t# Download data\n",
    "\tdf = yf.download(tickers=ticker, period=period, interval=interval, auto_adjust=True)\n",
    "\t\n",
    "\t# Flatten columns if multi-indexed\n",
    "\tif isinstance(df.columns, pd.MultiIndex):\n",
    "\t\tdf.columns = df.columns.get_level_values(0)\n",
    "\t\n",
    "\t# Convert index (Datetime) from UTC to US/Eastern\n",
    "\tdf.index = df.index.tz_convert('US/Eastern')\n",
    "\t\n",
    "\t# Save to CSV\n",
    "\tfilename = f\"{save_folder}{ticker}_{period}_{interval}.csv\"\n",
    "\tdf.to_csv(filename)\n",
    "\tprint(f\"{ticker} data saved to {filename}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b588c863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing AAPL_60d_30m.csv...\n",
      "Historically, the best day/time to BUY is Monday at 17:00:00 (avg close=209.20)\n",
      "Historically, the best day/time to SELL is Thursday at 15:00:00 (avg close=211.71)\n",
      "Saved heatmap to heatmaps\\AAPL_60d_30m_heatmap.png\n",
      "\n",
      "Processing GOOG_60d_30m.csv...\n",
      "Historically, the best day/time to BUY is Monday at 16:00:00 (avg close=183.98)\n",
      "Historically, the best day/time to SELL is Friday at 18:00:00 (avg close=186.37)\n",
      "Saved heatmap to heatmaps\\GOOG_60d_30m_heatmap.png\n",
      "\n",
      "Processing MSFT_60d_30m.csv...\n",
      "Historically, the best day/time to BUY is Wednesday at 18:30:00 (avg close=497.84)\n",
      "Historically, the best day/time to SELL is Thursday at 17:00:00 (avg close=501.04)\n",
      "Saved heatmap to heatmaps\\MSFT_60d_30m_heatmap.png\n",
      "\n",
      "Processing TSLA_60d_30m.csv...\n",
      "Historically, the best day/time to BUY is Thursday at 19:00:00 (avg close=318.87)\n",
      "Historically, the best day/time to SELL is Monday at 19:30:00 (avg close=324.61)\n",
      "Saved heatmap to heatmaps\\TSLA_60d_30m_heatmap.png\n",
      "\n",
      "Processing NVDA_60d_30m.csv...\n",
      "Historically, the best day/time to BUY is Monday at 13:30:00 (avg close=161.35)\n",
      "Historically, the best day/time to SELL is Thursday at 14:00:00 (avg close=164.52)\n",
      "Saved heatmap to heatmaps\\NVDA_60d_30m_heatmap.png\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# ---------------- List your CSV files ----------------\n",
    "csv_files = [\n",
    "    \"AAPL_60d_30m.csv\",\n",
    "    \"GOOG_60d_30m.csv\",\n",
    "    \"MSFT_60d_30m.csv\",\n",
    "    \"TSLA_60d_30m.csv\",\n",
    "    \"NVDA_60d_30m.csv\"\n",
    "]\n",
    "\n",
    "days = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\"]\n",
    "\n",
    "# Create output folder\n",
    "output_dir = \"heatmaps\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for file in csv_files:\n",
    "    print(f\"\\nProcessing {file}...\")\n",
    "    \n",
    "    # Load CSV\n",
    "    df = pd.read_csv(file)  # Must contain 'Datetime' and 'Close'\n",
    "    \n",
    "    # Sort and extract day and time\n",
    "    df[\"Datetime\"] = pd.to_datetime(df[\"Datetime\"], utc=True)\n",
    "    df = df.sort_values(\"Datetime\")\n",
    "    df[\"DayOfWeek\"] = df[\"Datetime\"].dt.dayofweek  # Monday=0\n",
    "    df[\"Time\"] = df[\"Datetime\"].dt.floor(\"30min\").dt.time\n",
    "    \n",
    "    # ---- Date Range ----\n",
    "    start_date = df[\"Datetime\"].min().strftime(\"%Y-%m-%d\")\n",
    "    end_date = df[\"Datetime\"].max().strftime(\"%Y-%m-%d\")\n",
    "    date_range_str = f\"{start_date} â†’ {end_date}\"\n",
    "    \n",
    "    # Compute average Close price per day+time\n",
    "    avg_price = df.groupby([\"DayOfWeek\", \"Time\"])[\"Close\"].mean().reset_index()\n",
    "    \n",
    "    # ---------------- Best Buy ----------------\n",
    "    best_buy = avg_price.loc[avg_price[\"Close\"].idxmin()]\n",
    "    best_buy_day = days[best_buy[\"DayOfWeek\"]]\n",
    "    best_buy_time = best_buy[\"Time\"]\n",
    "    \n",
    "    # ---------------- Best Sell ----------------\n",
    "    best_sell = avg_price.loc[avg_price[\"Close\"].idxmax()]\n",
    "    best_sell_day = days[best_sell[\"DayOfWeek\"]]\n",
    "    best_sell_time = best_sell[\"Time\"]\n",
    "    \n",
    "    print(f\"Historically, the best day/time to BUY is {best_buy_day} at {best_buy_time} \"\n",
    "          f\"(avg close={best_buy['Close']:.2f})\")\n",
    "    print(f\"Historically, the best day/time to SELL is {best_sell_day} at {best_sell_time} \"\n",
    "          f\"(avg close={best_sell['Close']:.2f})\")\n",
    "    \n",
    "    # ---------------- Heatmap ----------------\n",
    "    avg_price[\"TimeStr\"] = avg_price[\"Time\"].astype(str)\n",
    "    heatmap_data = avg_price.pivot(index=\"TimeStr\", columns=\"DayOfWeek\", values=\"Close\")\n",
    "    \n",
    "    plt.figure(figsize=(5, 4.5))\n",
    "    ax = sns.heatmap(heatmap_data, cmap=\"viridis\", cbar_kws={'label': 'Average Close Price'})\n",
    "    \n",
    "    # Invert y-axis\n",
    "    ax.invert_yaxis()\n",
    "    \n",
    "    # Highlight best buy\n",
    "    buy_x = best_buy[\"DayOfWeek\"] + 0.5\n",
    "    buy_y = list(heatmap_data.index).index(str(best_buy_time)) + 0.5\n",
    "    ax.scatter(buy_x, buy_y, color=\"red\", s=100, marker=\"o\", label=\"Best Buy\")\n",
    "    \n",
    "    # Highlight best sell\n",
    "    sell_x = best_sell[\"DayOfWeek\"] + 0.5\n",
    "    sell_y = list(heatmap_data.index).index(str(best_sell_time)) + 0.5\n",
    "    ax.scatter(sell_x, sell_y, color=\"green\", s=100, marker=\"X\", label=\"Best Sell\")\n",
    "    \n",
    "    # Labels, title, and legend outside\n",
    "    ax.set_xticks([i + 0.5 for i in range(5)])  # center of each cell\n",
    "    ax.set_xticklabels([\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\"])\n",
    "    ax.set_ylabel(\"Time of Day\")\n",
    "    ax.set_title(f\"{file}\\nAverage Close Price by Day & Time\\n({date_range_str})\", fontsize=10)\n",
    "    \n",
    "    # Move legend further right\n",
    "    ax.legend(loc='upper left', bbox_to_anchor=(1.4, 1))\n",
    "    \n",
    "    # Save PNG\n",
    "    stock_name = os.path.splitext(file)[0]  # remove .csv extension\n",
    "    out_path = os.path.join(output_dir, f\"{stock_name}_heatmap.png\")\n",
    "    plt.savefig(out_path, dpi=300, bbox_inches=\"tight\")\n",
    "    print(f\"Saved heatmap to {out_path}\")\n",
    "    \n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
